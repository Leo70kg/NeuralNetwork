Parallel Mode: Master-Slave
Dimension: 100
Total time: 0.25
Number of time intervals: 20
Learning rate: 0.0005
y_init_range: 0.25, 0.5
Number of neurons in each hidden layer of each subnet: 110, 110, 
Epochs: 4000
Batch size: 64
Sample size: 1024
Logging frequency: 100
Model name: AllenCahn_parallel_
Number of processors: 32


Training:
Epoch:100
In training set, loss: 18.8824, Y0: 0.246828

Epoch:200
In training set, loss: 18.4827, Y0: 0.243711

Epoch:300
In training set, loss: 18.0969, Y0: 0.240647

Epoch:400
In training set, loss: 17.7244, Y0: 0.237638

Epoch:500
In training set, loss: 17.3647, Y0: 0.234681

Epoch:600
In training set, loss: 17.0173, Y0: 0.231775

Epoch:700
In training set, loss: 16.6819, Y0: 0.228919

Epoch:800
In training set, loss: 16.3579, Y0: 0.226113

Epoch:900
In training set, loss: 16.0449, Y0: 0.223355

Epoch:1000
In training set, loss: 15.7425, Y0: 0.220644

Epoch:1100
In training set, loss: 15.4503, Y0: 0.217979

Epoch:1200
In training set, loss: 15.168, Y0: 0.21536

Epoch:1300
In training set, loss: 14.8952, Y0: 0.212786

Epoch:1400
In training set, loss: 14.6315, Y0: 0.210255

Epoch:1500
In training set, loss: 14.3767, Y0: 0.207767

Epoch:1600
In training set, loss: 14.1304, Y0: 0.205322

Epoch:1700
In training set, loss: 13.8922, Y0: 0.202917

Epoch:1800
In training set, loss: 13.662, Y0: 0.200552

Epoch:1900
In training set, loss: 13.4393, Y0: 0.198227

Epoch:2000
In training set, loss: 13.2241, Y0: 0.195942

Epoch:2100
In training set, loss: 13.016, Y0: 0.193694

Epoch:2200
In training set, loss: 12.8147, Y0: 0.191484

Epoch:2300
In training set, loss: 12.62, Y0: 0.189311

Epoch:2400
In training set, loss: 12.4317, Y0: 0.187173

Epoch:2500
In training set, loss: 12.2496, Y0: 0.185072

Epoch:2600
In training set, loss: 12.0734, Y0: 0.183005

Epoch:2700
In training set, loss: 11.903, Y0: 0.180972

Epoch:2800
In training set, loss: 11.7381, Y0: 0.178973

Epoch:2900
In training set, loss: 11.5786, Y0: 0.177006

Epoch:3000
In training set, loss: 11.4242, Y0: 0.175072

Epoch:3100
In training set, loss: 11.2749, Y0: 0.17317

Epoch:3200
In training set, loss: 11.1303, Y0: 0.171299

Epoch:3300
In training set, loss: 10.9905, Y0: 0.169458

Epoch:3400
In training set, loss: 10.8551, Y0: 0.167648

Epoch:3500
In training set, loss: 10.7241, Y0: 0.165867

Epoch:3600
In training set, loss: 10.5973, Y0: 0.164115

Epoch:3700
In training set, loss: 10.4746, Y0: 0.162392

Epoch:3800
In training set, loss: 10.3558, Y0: 0.160696

Epoch:3900
In training set, loss: 10.2408, Y0: 0.159029

Epoch:4000
In training set, loss: 10.1295, Y0: 0.157388



###############################################################################
TCHPC Cluster: kelvin
Job 22688 (BSDE_job_4_procs) for User 'zuoy' in Account 'hpc_21_01207'
Finished at: Sun Nov 21 18:08:34 GMT 2021

Job efficiency estimates:
=========================

Job ID: 22688
Cluster: kelvin
User/Group: zuoy/zuoy
State: COMPLETED (exit code 0)
Nodes: 3
Cores per node: 12
CPU Utilized: 03:07:26
CPU Efficiency: 30.27% of 10:19:12 core-walltime
Job Wall-clock time: 00:17:12
Memory Utilized: 655.11 MB
Memory Efficiency: 0.95% of 67.38 GB

Job completion status:
======================

       JobID    JobName AllocCPUS NTasks NNodes     MaxRSS    MaxRSSNode  MaxDiskRead MaxDiskWrite    Elapsed      State ExitCode 
------------ ---------- --------- ------ ------ ---------- ------------- ------------ ------------ ---------- ---------- -------- 
22688        BSDE_job_+        36             3                                                      00:17:12  COMPLETED      0:0 
22688.batch       batch        12      1      1    670832K   kelvin-n051        0.86M        0.01M   00:17:12  COMPLETED      0:0 
22688.0           orted        24      2      2                                                      00:17:11  COMPLETED      0:0 


Job details:
============

JobId=22688 JobName=BSDE_job_4_procs
   UserId=zuoy(1582) GroupId=zuoy(1252) MCS_label=N/A
   Priority=10628556 Nice=0 Account=hpc_21_01207 QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   DerivedExitCode=0:0
   RunTime=00:17:12 TimeLimit=23:00:00 TimeMin=N/A
   SubmitTime=2021-11-21T15:16:05 EligibleTime=2021-11-21T15:16:05
   AccrueTime=2021-11-21T15:16:05
   StartTime=2021-11-21T17:51:22 EndTime=2021-11-21T18:08:34 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-11-21T17:51:22
   Partition=compute AllocNode:Sid=kelvin01:12189
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=kelvin-n[052,054]
   BatchHost=kelvin-n051
   NumNodes=2 NumCPUs=36 NumTasks=32 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   TRES=cpu=36,mem=69000M,node=3,billing=36
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   JOB_GRES=(null)
     Nodes=kelvin-n[051-052,054] CPU_IDs=0-11 Mem=23000 GRES=
   MinCPUsNode=1 MinMemoryNode=23000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/scripts/script_AllenCahn_d200_b64_n32.sh
   WorkDir=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel
   StdErr=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/output/slurm-22688.out
   StdIn=/dev/null
   StdOut=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/output/slurm-22688.out
   Power=
   NtasksPerTRES:0


Disk quota details:
===================

Quota Type           Name  Filesystem     Usage in MB     Limit in MB    % Used
-------------------------------------------------------------------------------
USER                 zuoy       /home             126          51,200     0.25%

GROUP              mschpc   /projects             999          51,200     1.95%
GROUP          pi-dgolden   /projects               0          51,200     0.00%


SLURM Bank Statement:
=====================

User           Usage |        Account     Usage | Account Limit Available (CPU hrs)
---------- --------- + -------------- --------- + ------------- ---------
zuoy          20,387 |   HPC_21_01207    20,387 |       100,000    79,613


Acknowledgements:
=================

Note that usage of TCHPC Resources *must* be acknowledged in all publications.

Please see this page for details relevant to this cluster:

http://www.tchpc.tcd.ie/resources/acknowledgementpolicy

################################################################################
