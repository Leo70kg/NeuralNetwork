Parallel Mode: Master-Slave
Dimension: 200
Total time: 1
Number of time intervals: 40
Learning rate: 0.01
y_init_range: 40, 50
Number of neurons in each hidden layer of each subnet: 110, 110, 
Epochs: 1000
Batch size: 64
Sample size: 256
Logging frequency: 100
Model name: pricing_default_risk_parallel_
Number of processors: 128


Training:
slurmstepd: error: *** JOB 23409 ON kelvin-n003 CANCELLED AT 2021-11-23T21:42:44 ***


###############################################################################
TCHPC Cluster: kelvin
Job 23409 (BSDE_job_4_procs) for User 'zuoy' in Account 'hpc_21_01207'
Finished at: Tue Nov 23 21:42:44 GMT 2021

Job efficiency estimates:
=========================

Job ID: 23409
Cluster: kelvin
User/Group: zuoy/zuoy
State: CANCELLED (exit code 0)
Nodes: 11
Cores per node: 12
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-11:12:00 core-walltime
Job Wall-clock time: 00:16:00
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 247.07 GB (22.46 GB/node)

Job completion status:
======================

       JobID    JobName AllocCPUS NTasks NNodes     MaxRSS    MaxRSSNode  MaxDiskRead MaxDiskWrite    Elapsed      State ExitCode 
------------ ---------- --------- ------ ------ ---------- ------------- ------------ ------------ ---------- ---------- -------- 
23409        BSDE_job_+       132            11                                                      00:16:00 CANCELLED+      0:0 
23409.batch       batch        12      1      1                                                      00:16:00  CANCELLED      0:0 
23409.0           orted       120     10     10                                                      00:15:59  CANCELLED      0:0 


Job details:
============

JobId=23409 JobName=BSDE_job_4_procs
   UserId=zuoy(1582) GroupId=zuoy(1252) MCS_label=N/A
   Priority=10749646 Nice=0 Account=hpc_21_01207 QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   DerivedExitCode=0:0
   RunTime=00:16:00 TimeLimit=23:00:00 TimeMin=N/A
   SubmitTime=2021-11-23T13:05:41 EligibleTime=2021-11-23T13:05:41
   AccrueTime=2021-11-23T13:05:41
   StartTime=2021-11-23T21:26:44 EndTime=2021-11-23T21:42:44 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-11-23T21:26:44
   Partition=compute AllocNode:Sid=kelvin01:24539
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=kelvin-n[003,012,014-015,017-018,020-022,024,092]
   BatchHost=kelvin-n003
   NumNodes=11 NumCPUs=132 NumTasks=128 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   TRES=cpu=132,mem=253000M,node=11,billing=132
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   JOB_GRES=(null)
     Nodes=kelvin-n[003,012,014-015,017-018,020-022,024,092] CPU_IDs=0-11 Mem=23000 GRES=
   MinCPUsNode=1 MinMemoryNode=23000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/scripts/script_PricingDefaultRisk_d200_b64_n128.sh
   WorkDir=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel
   StdErr=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/output/slurm-23409.out
   StdIn=/dev/null
   StdOut=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/parallel/output/slurm-23409.out
   Power=
   NtasksPerTRES:0


Disk quota details:
===================

Quota Type           Name  Filesystem     Usage in MB     Limit in MB    % Used
-------------------------------------------------------------------------------
USER                 zuoy       /home             138          51,200     0.27%

GROUP              mschpc   /projects             999          51,200     1.95%
GROUP          pi-dgolden   /projects               0          51,200     0.00%


SLURM Bank Statement:
=====================

User           Usage |        Account     Usage | Account Limit Available (CPU hrs)
---------- --------- + -------------- --------- + ------------- ---------
zuoy          27,988 |   HPC_21_01207    27,988 |       100,000    72,012


Acknowledgements:
=================

Note that usage of TCHPC Resources *must* be acknowledged in all publications.

Please see this page for details relevant to this cluster:

http://www.tchpc.tcd.ie/resources/acknowledgementpolicy

################################################################################
