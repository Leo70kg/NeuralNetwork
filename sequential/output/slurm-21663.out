Config data loaded successfully!
Dimension: 100
Total time: 1
Number of time intervals: 20
Learning rate: 0.01
y_init_range: 0, 1
Number of neurons in each hidden layer of each subnet: 110, 110, 
Epochs: 4000
Batch size: 128
Sample size: 256
Logging frequency: 100
Model name: HJBLQ_serial_


Training:
Epoch:100
In training set, loss: 56.2277, Y0: 3.85232

Epoch:200
In training set, loss: 13.7821, Y0: 4.33596

Epoch:300
In training set, loss: 11.6852, Y0: 4.40781

Epoch:400
In training set, loss: 10.4929, Y0: 4.42799

Epoch:500
In training set, loss: 9.55101, Y0: 4.44012

Epoch:600
In training set, loss: 8.7909, Y0: 4.4498

Epoch:700
In training set, loss: 8.16892, Y0: 4.45799

Epoch:800
In training set, loss: 7.6532, Y0: 4.46501

Epoch:900
In training set, loss: 7.22009, Y0: 4.47108

Epoch:1000
In training set, loss: 6.85199, Y0: 4.47634

Epoch:1100
In training set, loss: 6.53561, Y0: 4.48093

Epoch:1200
In training set, loss: 6.26085, Y0: 4.48496

Epoch:1300
In training set, loss: 6.0199, Y0: 4.4885

Epoch:1400
In training set, loss: 5.80675, Y0: 4.49163

Epoch:1500
In training set, loss: 5.61665, Y0: 4.49441

Epoch:1600
In training set, loss: 5.44583, Y0: 4.49687

Epoch:1700
In training set, loss: 5.29129, Y0: 4.49906

Epoch:1800
In training set, loss: 5.15059, Y0: 4.50104

Epoch:1900
In training set, loss: 5.02175, Y0: 4.5028

Epoch:2000
In training set, loss: 4.90317, Y0: 4.50439

Epoch:2100
In training set, loss: 4.79347, Y0: 4.50581

Epoch:2200
In training set, loss: 4.69152, Y0: 4.5071

Epoch:2300
In training set, loss: 4.5964, Y0: 4.50827

Epoch:2400
In training set, loss: 4.50728, Y0: 4.50932

Epoch:2500
In training set, loss: 4.42349, Y0: 4.51028

Epoch:2600
In training set, loss: 4.34444, Y0: 4.51115

Epoch:2700
In training set, loss: 4.26963, Y0: 4.51194

Epoch:2800
In training set, loss: 4.19861, Y0: 4.51266

Epoch:2900
In training set, loss: 4.13101, Y0: 4.51332

Epoch:3000
In training set, loss: 4.0665, Y0: 4.51393

Epoch:3100
In training set, loss: 4.00479, Y0: 4.51448

Epoch:3200
In training set, loss: 3.94564, Y0: 4.51499

Epoch:3300
In training set, loss: 3.88881, Y0: 4.51545

Epoch:3400
In training set, loss: 3.83409, Y0: 4.51588

Epoch:3500
In training set, loss: 3.78132, Y0: 4.51628

Epoch:3600
In training set, loss: 3.73035, Y0: 4.51664

Epoch:3700
In training set, loss: 3.68103, Y0: 4.51697

Epoch:3800
In training set, loss: 3.63323, Y0: 4.51728

Epoch:3900
In training set, loss: 3.58685, Y0: 4.51756

Epoch:4000
In training set, loss: 3.54179, Y0: 4.51783



###############################################################################
TCHPC Cluster: kelvin
Job 21663 (BSDE_job_1_procs) for User 'zuoy' in Account 'hpc_21_01207'
Finished at: Fri Nov 19 15:27:11 GMT 2021

Job efficiency estimates:
=========================

Job ID: 21663
Cluster: kelvin
User/Group: zuoy/zuoy
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 12
CPU Utilized: 00:31:05
CPU Efficiency: 8.32% of 06:13:24 core-walltime
Job Wall-clock time: 00:31:07
Memory Utilized: 9.96 MB
Memory Efficiency: 0.04% of 22.46 GB

Job completion status:
======================

       JobID    JobName AllocCPUS NTasks NNodes     MaxRSS    MaxRSSNode  MaxDiskRead MaxDiskWrite    Elapsed      State ExitCode 
------------ ---------- --------- ------ ------ ---------- ------------- ------------ ------------ ---------- ---------- -------- 
21663        BSDE_job_+        12             1                                                      00:31:07  COMPLETED      0:0 
21663.batch       batch        12      1      1     10204K   kelvin-n022        0.85M        0.01M   00:31:07  COMPLETED      0:0 


Job details:
============

JobId=21663 JobName=BSDE_job_1_procs
   UserId=zuoy(1582) GroupId=zuoy(1252) MCS_label=N/A
   Priority=11057855 Nice=0 Account=hpc_21_01207 QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   DerivedExitCode=0:0
   RunTime=00:31:07 TimeLimit=2-23:00:00 TimeMin=N/A
   SubmitTime=2021-11-19T14:30:10 EligibleTime=2021-11-19T14:30:10
   AccrueTime=2021-11-19T14:30:10
   StartTime=2021-11-19T14:56:04 EndTime=2021-11-19T15:27:11 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2021-11-19T14:56:04
   Partition=compute AllocNode:Sid=kelvin01:22213
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=
   BatchHost=kelvin-n022
   NumNodes=1 NumCPUs=12 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*
   TRES=cpu=12,mem=23000M,node=1,billing=12
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   JOB_GRES=(null)
     Nodes=kelvin-n022 CPU_IDs=0-11 Mem=23000 GRES=
   MinCPUsNode=1 MinMemoryNode=23000M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/sequential/scripts/script_HJBLQ_d100_b128.sh
   WorkDir=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/sequential
   StdErr=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/sequential/output/slurm-21663.out
   StdIn=/dev/null
   StdOut=/home/users/mschpc/2019/zuoy/HPC/NeuralNetwork/sequential/output/slurm-21663.out
   Power=
   NtasksPerTRES:0


Disk quota details:
===================

Quota Type           Name  Filesystem     Usage in MB     Limit in MB    % Used
-------------------------------------------------------------------------------
USER                 zuoy       /home             109          51,200     0.21%

GROUP              mschpc   /projects             999          51,200     1.95%
GROUP          pi-dgolden   /projects               0          51,200     0.00%


SLURM Bank Statement:
=====================

User           Usage |        Account     Usage | Account Limit Available (CPU hrs)
---------- --------- + -------------- --------- + ------------- ---------
zuoy          10,591 |   HPC_21_01207    10,591 |       100,000    89,409


Acknowledgements:
=================

Note that usage of TCHPC Resources *must* be acknowledged in all publications.

Please see this page for details relevant to this cluster:

http://www.tchpc.tcd.ie/resources/acknowledgementpolicy

################################################################################
